{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the Predictive Power of TPOT vs XGBoost Quick and Dirty Stylee\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a quick and dirty look at how TPOT compares to XGBoost with minimal tuning.  \n",
    "#### I am using https://www.kaggle.com/sampadab17/network-intrusion-detection network security dataset from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and custom cell behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# see all the data in dataframe\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# widen jupyter cells to page width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Train_data.csv')\n",
    "# df_test = pd.read_csv('Test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===================  Preprocess data  =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration                       0\n",
       "protocol_type                  0\n",
       "service                        0\n",
       "flag                           0\n",
       "src_bytes                      0\n",
       "dst_bytes                      0\n",
       "land                           0\n",
       "wrong_fragment                 0\n",
       "urgent                         0\n",
       "hot                            0\n",
       "num_failed_logins              0\n",
       "logged_in                      0\n",
       "num_compromised                0\n",
       "root_shell                     0\n",
       "su_attempted                   0\n",
       "num_root                       0\n",
       "num_file_creations             0\n",
       "num_shells                     0\n",
       "num_access_files               0\n",
       "num_outbound_cmds              0\n",
       "is_host_login                  0\n",
       "is_guest_login                 0\n",
       "count                          0\n",
       "srv_count                      0\n",
       "serror_rate                    0\n",
       "srv_serror_rate                0\n",
       "rerror_rate                    0\n",
       "srv_rerror_rate                0\n",
       "same_srv_rate                  0\n",
       "diff_srv_rate                  0\n",
       "srv_diff_host_rate             0\n",
       "dst_host_count                 0\n",
       "dst_host_srv_count             0\n",
       "dst_host_same_srv_rate         0\n",
       "dst_host_diff_srv_rate         0\n",
       "dst_host_same_src_port_rate    0\n",
       "dst_host_srv_diff_host_rate    0\n",
       "dst_host_serror_rate           0\n",
       "dst_host_srv_serror_rate       0\n",
       "dst_host_rerror_rate           0\n",
       "dst_host_srv_rerror_rate       0\n",
       "class                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another one line check, less info but same check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode data to machine optimized format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df_train, prefix=['protocol_type', 'service', 'flag'], columns=['protocol_type', 'service', 'flag'])\n",
    "# df_test_encoded = pd.get_dummies(df_test, prefix=['protocol_type', 'service', 'flag'], columns=['protocol_type', 'service', 'flag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab X and y values from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop('class', axis=1).values\n",
    "y = df_encoded['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize data\n",
    "####  Standarize darta between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = std_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode target variables for machine handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "y_encoded = labelencoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train/test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y_encoded, test_size=0.2, random_state=93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==========================  XGBoost  ===================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load XGB Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(n_jobs=-1, random_state=93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and predict on XGB Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print XGB Classifier accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9954356023020441"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, preds)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================  TPOT  ===================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TPOT classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_optimizer = TPOTClassifier(generations=10, population_size=100, n_jobs=-1, cv=2, random_state=93, verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TPOT does exahustive pipeline searches.  This WILL take a long time without adjusting <em>generations</em> and <em>population</em> size.  Knocking down <em>population</em> size will shorten the run time to see if it's working before kicking off exhaustive search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3489bdccf4d04e1ead17ffbbfc0f136a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=1100, style=ProgressStyle(descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.9968738825375691\n",
      "Generation 2 - Current best internal CV score: 0.9968738973106761\n",
      "Generation 3 - Current best internal CV score: 0.9968738973106761\n",
      "Generation 4 - Current best internal CV score: 0.997072388775543\n",
      "Generation 5 - Current best internal CV score: 0.9972708556185652\n",
      "Generation 6 - Current best internal CV score: 0.9972708556185652\n",
      "Generation 7 - Current best internal CV score: 0.9974197094441085\n",
      "Generation 8 - Current best internal CV score: 0.9974197094441085\n",
      "Generation 9 - Current best internal CV score: 0.9974197094441085\n",
      "Generation 10 - Current best internal CV score: 0.9974197094441085\n",
      "\n",
      "Best pipeline: GradientBoostingClassifier(input_matrix, learning_rate=0.5, max_depth=9, max_features=0.4, min_samples_leaf=19, min_samples_split=2, n_estimators=100, subsample=0.9500000000000001)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=2,\n",
       "        disable_update_check=False, early_stop=None, generations=10,\n",
       "        max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
       "        mutation_rate=0.9, n_jobs=-1, offspring_size=None,\n",
       "        periodic_checkpoint_folder=None, population_size=100,\n",
       "        random_state=93, scoring=None, subsample=1.0,\n",
       "        template='RandomTree', use_dask=False, verbosity=2,\n",
       "        warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_optimizer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print TPOT accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9978170271879341\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_optimizer.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Score Comparison\n",
    "\n",
    "XGBoost = 0.9954356023020441 <br />\n",
    "TPOT = 0.9978170271879341"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see that TPOT out performs XGBoost with default params out of the bag but takes <em>much</em> longer to train. \n",
    "#### TPOT beats XGBoost by 0.002% with a vanilla train but train time and parameter tuning could show us different results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
